{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kod bezproblemowo uruchamia się na komputerze innym niż grupy modelującej. Proces EDA przeprowadzony bez zastrzeżeń. Podczas preprocessingu zastosowano sensowne transformacje danych i sprawdzono ich skuteczność. Cały proces został zautomatyzowany pipelinami co znacząco zwiększa przejrzystość kodu. Podczas oceny jakości modelu użyto wielu metryk,którę mają uzasadnienie i interpretację biznesową przy zastosowaniu modelu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uwagi:\n",
    "- w pliku model_and_hyperparameters w komórce pod napisem Ostateczne Wykresy kilka razy przypisujecie różne modele do zmiennej xgb1 i xgb2 (ostatecznie do ewaluacji trafia xgb1 i xgb2 bez pipeline)\n",
    "- brak wniosku który lub które modele są według was najlepsze?\n",
    "- wytrenowane, najlepsze według was modele można zapisać do pliku pkl co ułatwi korzystanie z kodu innym użytkownikom\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sprawdzamy perforamance modeli na danych walidacyjnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 17\n",
    "bank_data = pd.read_csv(\"./Data/bank_train_data.csv\", index_col=0)\n",
    "\n",
    "## Kategoryczne niebinarne\n",
    "# Oridinal education\n",
    "bank_data['education'] = bank_data['education'].map({'unknown': 0, 'primary': 1, 'secondary': 2, 'tertiary': 3})\n",
    "\n",
    "# OneHot reszty\n",
    "bank_data = pd.get_dummies(bank_data, columns=['job','contact','marital','poutcome'])\n",
    "\n",
    "## Kategoryczne binarne\n",
    "binary = [\"default\", \"housing\", \"loan\", \"y\"]\n",
    "for col in binary:\n",
    "    bank_data[col] = bank_data[col].map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "# Month (tranfosrmacja na okrąg)\n",
    "bank_data['month'] = bank_data[\"month\"].map({\"jan\": 0, \"feb\": 1, \"mar\": 2, \"apr\": 3, \"may\": 4, \"jun\": 5, \"jul\": 6, \"aug\": 7, \"sep\": 8, \"oct\": 9, \"nov\": 10, \"dec\": 11})\n",
    "bank_data['month'] = bank_data[\"month\"].apply(lambda x: np.sin(x * (2 * np.pi / 12)))\n",
    "\n",
    "# Day (transformacja na okrąg)\n",
    "bank_data['day'] = bank_data[\"day\"].apply(lambda x: np.sin(x * (2 * np.pi / 31)))\n",
    "X = bank_data.drop(\"y\", axis=1)\n",
    "y = bank_data[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ramka danych i preproccesing wstępny\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 17\n",
    "bank_data = pd.read_csv(\"./Dont use this/bank_val_data.csv\", index_col=0)\n",
    "\n",
    "## Kategoryczne niebinarne\n",
    "# Oridinal education\n",
    "bank_data['education'] = bank_data['education'].map({'unknown': 0, 'primary': 1, 'secondary': 2, 'tertiary': 3})\n",
    "\n",
    "# OneHot reszty\n",
    "bank_data = pd.get_dummies(bank_data, columns=['job','contact','marital','poutcome'])\n",
    "\n",
    "## Kategoryczne binarne\n",
    "binary = [\"default\", \"housing\", \"loan\", \"y\"]\n",
    "for col in binary:\n",
    "    bank_data[col] = bank_data[col].map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "# Month (tranfosrmacja na okrąg)\n",
    "bank_data['month'] = bank_data[\"month\"].map({\"jan\": 0, \"feb\": 1, \"mar\": 2, \"apr\": 3, \"may\": 4, \"jun\": 5, \"jul\": 6, \"aug\": 7, \"sep\": 8, \"oct\": 9, \"nov\": 10, \"dec\": 11})\n",
    "bank_data['month'] = bank_data[\"month\"].apply(lambda x: np.sin(x * (2 * np.pi / 12)))\n",
    "\n",
    "# Day (transformacja na okrąg)\n",
    "bank_data['day'] = bank_data[\"day\"].apply(lambda x: np.sin(x * (2 * np.pi / 31)))\n",
    "X_val = bank_data.drop(\"y\", axis=1)\n",
    "y_val = bank_data[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Klasa do wyrzucania kolumn w pipelinie\n",
    "class ColumnDropper(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.drop(self.columns, axis = 1)\n",
    "    \n",
    "# Klasa do logarytmowania i następnie standaryzowania kolumn\n",
    "class LogStdTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.std_scalers = [StandardScaler() for _ in range(len(columns))]\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        for i, col in enumerate(self.columns):\n",
    "            self.std_scalers[i].fit(np.log1p(X[[col]]))\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        df = X.copy()\n",
    "        \n",
    "        for i, col in enumerate(self.columns):\n",
    "            df[col] = self.std_scalers[i].transform(np.log1p(X[[col]]))\n",
    "        \n",
    "        return df\n",
    "\n",
    "# Klasa do binnowania cechy balance\n",
    "class BalanceBinner(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        curr_balance = X[\"balance\"]\n",
    "        new_balance = balance = pd.cut(curr_balance, bins = [-np.inf, 0, 1500, np.inf], labels=[0, 1, 2]).cat.codes\n",
    "        return X.drop(\"balance\", axis=1).assign(balance = new_balance)\n",
    "    \n",
    "# Klasa do transoformowania cech na przedział (0, 1) (jednostajnie)\n",
    "class MinMaxTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.scalers = [MinMaxScaler() for i in range(len(columns))]\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        for i, col in enumerate(self.columns):\n",
    "            self.scalers[i].fit(X[[col]])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        df = X.copy()\n",
    "        \n",
    "        for i, col in enumerate(self.columns):\n",
    "            df[col] = self.scalers[i].transform(X[[col]])\n",
    "        \n",
    "        return df\n",
    "\n",
    "# Klasa do binnowania cechy previous\n",
    "class PreviousBinner(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.assign(previous = np.where(X[\"previous\"] == 0, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, accuracy_score, confusion_matrix, fbeta_score, roc_curve, auc, recall_score, f1_score,balanced_accuracy_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Do plotowania krzywej roc\n",
    "def plot_roc_curve(model, title_model, X_test, y_test):\n",
    "    fpr, tpr, threshold = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, 'b', label = \"AUC = %0.2f\" % roc_auc)\n",
    "    plt.title(\"ROC for: \" + str(title_model).split('(')[0])\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.plot([0, 1], [0, 1], \"r--\")\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.show()\n",
    "    \n",
    "# Funkcja do badania podstawowych scorów do baselinu\n",
    "def base_test_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat = model.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_hat)\n",
    "    g_mean = geometric_mean_score(y_test, y_hat)\n",
    "    accuracy = accuracy_score(y_test, y_hat)\n",
    "    fbeta = fbeta_score(y_test, y_hat, beta=0.5)\n",
    "    recall = recall_score(y_test,y_hat)\n",
    "    print(\"Precision score:\", precision)\n",
    "    print(\"G-mean score:   \", g_mean)\n",
    "    print(\"Accuracy score: \", accuracy)\n",
    "    print(\"Fbeta_score:    \", fbeta)\n",
    "    print(\"Recall score:\", recall)\n",
    "    print(\"Confusion matrix: \\n\", confusion_matrix(y_test, y_hat))\n",
    "    return precision, g_mean, accuracy, fbeta, recall\n",
    "\n",
    "def custom_fbeta_scorer(estimator, X, y):\n",
    "    y_hat = estimator.predict(X)\n",
    "    return fbeta_score(y, y_hat, beta=0.5)\n",
    "\n",
    "def get_auc(model, X_test, y_test):\n",
    "    fpr, tpr, threshold = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    return auc(fpr, tpr)   \n",
    "\n",
    "def custom_auc_scorer(estimator, X, y):\n",
    "    return get_auc(estimator, X, y)\n",
    "\n",
    "def custom_gmean_scorer(estimator, X, y):\n",
    "    return geometric_mean_score(y, estimator.predict(X))\n",
    "\n",
    "def get_my_pipe_with_model(model):\n",
    "    pipe = Pipeline([\n",
    "        (\"dropper\", ColumnDropper([\"pdays\", \"default\", 'poutcome_unknown', 'poutcome_other', 'contact_unknown', 'job_unknown'])),\n",
    "        (\"balance_binner\", BalanceBinner()),\n",
    "        (\"bin_previous\", PreviousBinner()),\n",
    "        (\"transformer _ minmax\", MinMaxTransformer([\"duration\", \"age\", \"campaign\"])),\n",
    "        (\"model\", model)\n",
    "        ])\n",
    "    return pipe\n",
    "\n",
    "def crosswalidate_model_plot(model_cal, param_dict, X, y, n_repeats):\n",
    "    skf = RepeatedStratifiedKFold(n_splits=5, n_repeats=n_repeats, random_state=seed)\n",
    "    stats = {\"precision\": np.array([]), \"g-mean\": np.array([]), \"accuracy\": np.array([]), \"fbeta\": np.array([]), \"recall\": np.array([]), \"auc_score\": np.array([])}\n",
    "    \n",
    "    for i, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        model = model_cal(**param_dict)\n",
    "        pipe = get_my_pipe_with_model(model)\n",
    "        pipe.fit(X.loc[train_idx], y.loc[train_idx])\n",
    "        y_hat = pipe.predict(X.loc[test_idx])\n",
    "        \n",
    "        stats[\"precision\"] = np.append(stats[\"precision\"], precision_score(y.loc[test_idx], y_hat))\n",
    "        stats[\"g-mean\"] = np.append(stats[\"g-mean\"], geometric_mean_score(y.loc[test_idx], y_hat))\n",
    "        stats[\"accuracy\"] = np.append(stats[\"accuracy\"], accuracy_score(y.loc[test_idx], y_hat))\n",
    "        stats[\"fbeta\"] = np.append(stats[\"fbeta\"], fbeta_score(y.loc[test_idx], y_hat, beta=0.5))\n",
    "        stats[\"recall\"] = np.append(stats[\"recall\"], recall_score(y.loc[test_idx], y_hat))\n",
    "        stats[\"auc_score\"] = np.append(stats[\"auc_score\"], get_auc(pipe, X.loc[test_idx], y.loc[test_idx]))\n",
    "    \n",
    "    df = pd.DataFrame(data=stats, columns=[\"precision\", \"g-mean\", \"accuracy\", \"fbeta\", \"recall\", \"auc_score\"])\n",
    "    ax = sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(df))\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_title(\"Crosswalidation results for: \" + str(model))\n",
    "    plt.show()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def evaluate_model(model, X, y, scoring):\n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=17)\n",
    "    scores = cross_val_score(model, X, y, scoring=scoring, cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametry RandomForest\n",
    "dict_forest_fbeta = {\n",
    "    'criterion': 'gini',\n",
    "    'max_depth': 15, \n",
    "    'max_features': 7, \n",
    "    'min_samples_split': 8, \n",
    "    'n_estimators': 149,\n",
    "    \"random_state\": 17\n",
    "}\n",
    "dict_forest_gmean = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 145,\n",
    "    'criterion': 'gini',\n",
    "    'max_depth': 21,\n",
    "    'min_samples_split': 2,\n",
    "    'random_state': 17\n",
    "}\n",
    "# Parametry GradientBooster\n",
    "dict_gradient_fbeta = {\n",
    "    'l2_regularization': 10, \n",
    "    'learning_rate': 0.05, \n",
    "    'max_depth': 2, \n",
    "    'max_iter': 1000, \n",
    "    'max_leaf_nodes': 10, \n",
    "    'random_state': 17\n",
    "}\n",
    "dict_gradient_gmean = {\n",
    "    'l2_regularization': 0.5,\n",
    "    'learning_rate': 0.2,\n",
    "    'max_depth': 3,\n",
    "    'max_leaf_nodes': 10,\n",
    "    'max_iter': 1000,\n",
    "    'random_state': 17\n",
    "}\n",
    "# Parametry XGBoost\n",
    "dict_xgboost_fbeta = {\n",
    "    'alpha': 1, \n",
    "    'eta': 0.2, \n",
    "    'gamma': 0, \n",
    "    'lambda': 5, \n",
    "    'max_depth': 12, \n",
    "    'min_child_weight': 1, \n",
    "    'random_state': 17, \n",
    "    'scale_pos_weight': 7.67\n",
    "}\n",
    "dict_xgboost_gmean = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'gamma': 5,\n",
    "    'min_child_weight': 20,\n",
    "    'lambda': 0.5,\n",
    "    'alpha': 5,\n",
    "    'scale_pos_weight': 7.67,\n",
    "    'random_state': 17\n",
    "}\n",
    "# Parametry SVM\n",
    "dict_svm_fbeta = {\n",
    "    'kernel': 'poly',\n",
    "    'degree': 1,\n",
    "    'max_iter': 150000,\n",
    "    'random_state': 17,\n",
    "    'probability': True\n",
    "}\n",
    "dict_svm_gmean = {\n",
    "    'degree': 7, \n",
    "    'kernel': 'poly', \n",
    "    'max_iter': 150000, \n",
    "    'random_state': 17,\n",
    "    'probability': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenowanie modeli na danych grupy modelującej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = get_my_pipe_with_model(RandomForestClassifier(**dict_forest_fbeta))\n",
    "rf2 = get_my_pipe_with_model(RandomForestClassifier(**dict_forest_gmean))\n",
    "gra1 = get_my_pipe_with_model(HistGradientBoostingClassifier(**dict_gradient_fbeta))\n",
    "gra2 = get_my_pipe_with_model(HistGradientBoostingClassifier(**dict_gradient_gmean))\n",
    "xgb1 = get_my_pipe_with_model(XGBClassifier(**dict_xgboost_fbeta))\n",
    "xgb2 = get_my_pipe_with_model(XGBClassifier(**dict_xgboost_gmean))\n",
    "svc1 = get_my_pipe_with_model(SVC(**dict_svm_fbeta))\n",
    "svc2 = get_my_pipe_with_model(SVC(**dict_svm_gmean))\n",
    "\n",
    "# Definicja modelu stacked\n",
    "xgb3 = XGBClassifier(**dict_xgboost_fbeta)\n",
    "xgb4 = XGBClassifier(**dict_xgboost_gmean)\n",
    "level0 = [(\"beta\", xgb3), (\"gmean\", xgb4)]\n",
    "level1 = LogisticRegression()\n",
    "stacked = get_my_pipe_with_model(StackingClassifier(estimators=level0, final_estimator=level1, cv=5))\n",
    "\n",
    "# Definicja modelu soft\n",
    "xgb5 = XGBClassifier(**dict_xgboost_fbeta)\n",
    "xgb6 = XGBClassifier(**dict_xgboost_gmean)\n",
    "level0 = [(\"beta\", xgb5), (\"gmean\", xgb6)]\n",
    "soft = get_my_pipe_with_model(VotingClassifier(estimators=level0, voting=\"soft\"))\n",
    "\n",
    "models = [rf1, rf2, gra1, gra2, xgb1, xgb2, svc1, svc2, stacked, soft]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X,y)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprawdzenie wyników modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF-beta\n",
      "precision: 0.5853658536585366\n",
      "gmean: 0.546792115783077\n",
      "fbeta: 0.49586776859504134\n",
      "balanced accuracy: 0.6396912829052712\n",
      "recall: 0.3076923076923077\n",
      "\n",
      "RF-gmean\n",
      "precision: 0.5970149253731343\n",
      "gmean: 0.5006454127726119\n",
      "fbeta: 0.4716981132075472\n",
      "balanced accuracy: 0.6169644953991331\n",
      "recall: 0.2564102564102564\n",
      "\n",
      "GRA-beta\n",
      "precision: 0.5760869565217391\n",
      "gmean: 0.5733333382983868\n",
      "fbeta: 0.5057251908396947\n",
      "balanced accuracy: 0.6536353252631355\n",
      "recall: 0.33974358974358976\n",
      "\n",
      "GRA-gmean\n",
      "precision: 0.5405405405405406\n",
      "gmean: 0.6068631157205541\n",
      "fbeta: 0.5\n",
      "balanced accuracy: 0.6710753858963684\n",
      "recall: 0.38461538461538464\n",
      "\n",
      "XGB-beta\n",
      "precision: 0.5194805194805194\n",
      "gmean: 0.693702322707771\n",
      "fbeta: 0.5181347150259067\n",
      "balanced accuracy: 0.725602596127159\n",
      "recall: 0.5128205128205128\n",
      "\n",
      "XGB-gmean\n",
      "precision: 0.39197530864197533\n",
      "gmean: 0.8249638421460896\n",
      "fbeta: 0.43732782369146006\n",
      "balanced accuracy: 0.825036294540874\n",
      "recall: 0.8141025641025641\n",
      "\n",
      "SVM-beta\n",
      "precision: 0.5555555555555556\n",
      "gmean: 0.3556643780462908\n",
      "fbeta: 0.3333333333333333\n",
      "balanced accuracy: 0.5574414483656782\n",
      "recall: 0.1282051282051282\n",
      "\n",
      "SVM-gmean\n",
      "precision: 0.5\n",
      "gmean: 0.45357027853038473\n",
      "fbeta: 0.39285714285714285\n",
      "balanced accuracy: 0.5920306795619035\n",
      "recall: 0.21153846153846154\n",
      "\n",
      "Stacked\n",
      "precision: 0.5980392156862745\n",
      "gmean: 0.6145540841858117\n",
      "fbeta: 0.5407801418439716\n",
      "balanced accuracy: 0.6784437114370503\n",
      "recall: 0.391025641025641\n",
      "\n",
      "Soft\n",
      "precision: 0.49\n",
      "gmean: 0.7581900507921896\n",
      "fbeta: 0.5125523012552301\n",
      "balanced accuracy: 0.7716379512799163\n",
      "recall: 0.6282051282051282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_names = [\"RF-beta\", \"RF-gmean\", \"GRA-beta\", \"GRA-gmean\", \"XGB-beta\", \"XGB-gmean\", \"SVM-beta\", \"SVM-gmean\", \"Stacked\", \"Soft\"]\n",
    "\n",
    "i = 0\n",
    "for model in models:\n",
    "    y_hat = model.predict(X_val)\n",
    "    print(model_names[i])\n",
    "    print(\"precision: \" + str(precision_score(y_val, y_hat)))\n",
    "    print(\"gmean: \" + str(geometric_mean_score(y_val, y_hat)))\n",
    "    print(\"fbeta: \" + str(fbeta_score(y_val, y_hat,beta=0.5)))\n",
    "    print(\"balanced accuracy: \" + str(balanced_accuracy_score(y_val, y_hat)))\n",
    "    print(\"recall: \" + str(recall_score(y_val, y_hat)))\n",
    "    print()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('jupyter nbconvert --to html validation.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
